{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BmHwXsIkZ6ZF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmHwXsIkZ6ZF",
        "outputId": "7b22df96-d839-4952-9815-edae0c5d61bd"
      },
      "outputs": [],
      "source": [
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"ðŸ“ Running in Google Colab - Installing Ollama...\")\n",
        "    # Install Ollama in Colab\n",
        "    !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "    # Start Ollama server in background\n",
        "    import subprocess\n",
        "    import time\n",
        "\n",
        "    # Start server\n",
        "    ollama_process = subprocess.Popen(['ollama', 'serve'],\n",
        "                                      stdout=subprocess.PIPE,\n",
        "                                      stderr=subprocess.PIPE)\n",
        "    time.sleep(5)  # Wait for server to start\n",
        "\n",
        "    # Pull LLaMA 3 model\n",
        "    !ollama pull llama3\n",
        "\n",
        "    print(\"âœ… Ollama installed and started successfully!\")\n",
        "else:\n",
        "    print(\"ðŸ“ Running locally - Please ensure Ollama is installed and running\")\n",
        "    print(\"   Install: curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "    print(\"   Start server: ollama serve\")\n",
        "    print(\"   Pull model: ollama pull llama3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d99ae58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d99ae58",
        "outputId": "5c896007-f808-4760-f35f-d50be5fcbd4a"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import requests\n",
        "except ImportError:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
        "    import requests\n",
        "import re, json\n",
        "\n",
        "class OllamaClient:\n",
        "    def __init__(self):\n",
        "        self.base_url = config.ollama_base_url\n",
        "        self.model = config.ollama_model\n",
        "        self.api_url = f\"{self.base_url}/api/generate\"\n",
        "    def call(self, prompt: str) -> dict:\n",
        "        response = requests.post(\n",
        "            self.api_url,\n",
        "            json={\n",
        "                \"model\": self.model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"temperature\": config.ollama_temperature,\n",
        "                \"options\": {\"num_predict\": 4096, \"top_k\": 40, \"top_p\": 0.9}\n",
        "            },\n",
        "            timeout=config.ollama_timeout\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        raw_text = response.json().get(\"response\", \"\")\n",
        "        cleaned = re.sub(r'```json\\\\s*', '', raw_text)\n",
        "        cleaned = re.sub(r'```\\\\s*', '', cleaned)\n",
        "        match = re.search(r'\\{.*\\}', cleaned, re.DOTALL)\n",
        "        return json.loads(match.group(0) if match else cleaned.strip())\n",
        "    def test_connection(self) -> bool:\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\", timeout=5)\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "ollama = OllamaClient()\n",
        "print(\"Ollama connection:\", \"OK\" if ollama.test_connection() else \"FAILED\")\n",
        "\n",
        "# Example LLM call (replace with real prompt for actual use)\n",
        "# sample_prompt = \"{\"institution\": {\"name\": \"Test U\", \"confidence_score\": 1.0}, \"programs\": []}\"\n",
        "# print(ollama.call(sample_prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d01685",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import json\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datetime import datetime\n",
        "\n",
        "# Install required packages\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "try:\n",
        "    from pydantic import BaseModel, Field, ConfigDict, ValidationError\n",
        "except ImportError:\n",
        "    install_package(\"pydantic\")\n",
        "    from pydantic import BaseModel, Field, ConfigDict, ValidationError\n",
        "\n",
        "try:\n",
        "    from pymongo import MongoClient\n",
        "    from pymongo.errors import ConnectionFailure, OperationFailure\n",
        "except ImportError:\n",
        "    install_package(\"pymongo\")\n",
        "    from pymongo import MongoClient\n",
        "    from pymongo.errors import ConnectionFailure, OperationFailure\n",
        "\n",
        "try:\n",
        "    import requests\n",
        "except ImportError:\n",
        "    install_package(\"requests\")\n",
        "    import requests\n",
        "\n",
        "print(\"âœ“ All dependencies loaded successfully\")\n",
        "\n",
        "\n",
        "# ## Data Models (Pydantic Schemas)\n",
        "\n",
        "\n",
        "class Institution(BaseModel):\n",
        "    name: str = Field(..., description=\"Official institution name\")\n",
        "    institution_code: Optional[str] = Field(None, description=\"Unique identifier\")\n",
        "    description: Optional[str] = Field(None, description=\"Institution overview\")\n",
        "    type: List[str] = Field(default_factory=list, description=\"Institution types\")\n",
        "    country: str = Field(default=\"Sri Lanka\", description=\"Country\")\n",
        "    website: Optional[str] = Field(None, description=\"Website URL\")\n",
        "    recognition: Optional[Dict[str, Any]] = Field(None, description=\"Accreditation\")\n",
        "    contact_info: Optional[Dict[str, Any]] = Field(None, description=\"Contact details\")\n",
        "    confidence_score: float = Field(..., ge=0.0, le=1.0, description=\"Confidence (0-1)\")\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "\n",
        "class Program(BaseModel):\n",
        "    name: str = Field(..., description=\"Program name\")\n",
        "    program_code: Optional[str] = Field(None, description=\"Unique identifier\")\n",
        "    description: Optional[str] = Field(None, description=\"Program overview\")\n",
        "    level: Optional[str] = Field(None, description=\"Academic level\")\n",
        "    duration: Optional[Dict[str, Any]] = Field(None, description=\"Duration details\")\n",
        "    delivery_mode: Optional[List[str]] = Field(None, description=\"Delivery modes\")\n",
        "    fees: Optional[Dict[str, Any]] = Field(None, description=\"Fee structure\")\n",
        "    eligibility: Optional[Dict[str, Any]] = Field(None, description=\"Requirements\")\n",
        "    curriculum_summary: Optional[str] = Field(None, description=\"Curriculum overview\")\n",
        "    specializations: Optional[List[str]] = Field(None, description=\"Specializations\")\n",
        "    url: Optional[str] = Field(None, description=\"Program or institution URL if present in text\")\n",
        "    extensions: Optional[Dict[str, Any]] = Field(None, description=\"Additional data\")\n",
        "    confidence_score: float = Field(..., ge=0.0, le=1.0, description=\"Confidence (0-1)\")\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "\n",
        "print(\"âœ“ Data models defined\")\n",
        "\n",
        "\n",
        "# ## Configuration\n",
        "\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    \"OLLAMA_BASE_URL\": \"http://localhost:11434\",\n",
        "    \"OLLAMA_MODEL\": \"llama3\",  # Updated to match available model\n",
        "    \"MONGODB_URI\": \"mongodb+srv://ict22006_db_user:gGgnHUqamNcU5jAy@development.ps1jayw.mongodb.net/?appName=development\",\n",
        "    \"DATABASE_NAME\": \"education_db\",\n",
        "    \"COLLECTION_INSTITUTIONS\": \"institutions\",\n",
        "    \"COLLECTION_PROGRAMS\": \"programs\",\n",
        "    \"DATA_FOLDER\": \"./data\",  # Folder containing text files\n",
        "    \"MAX_RETRIES\": 2,\n",
        "    \"TIMEOUT\": 60\n",
        "}\n",
        "\n",
        "print(\"âœ“ Configuration loaded\")\n",
        "\n",
        "\n",
        "# ## Ollama LLM Integration\n",
        "\n",
        "\n",
        "class OllamaClient:\n",
        "    \"\"\"Handles communication with Ollama local LLM\"\"\"\n",
        "    \n",
        "    def __init__(self, base_url: str, model: str, timeout: int = 60):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.model = model\n",
        "        self.timeout = timeout\n",
        "        self._check_connection()\n",
        "    \n",
        "    def _check_connection(self):\n",
        "        \"\"\"Verify Ollama is running\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\", timeout=5)\n",
        "            response.raise_for_status()\n",
        "            print(f\"âœ“ Connected to Ollama at {self.base_url}\")\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Ollama: {e}\")\n",
        "    \n",
        "    def generate(self, prompt: str, system_prompt: str = None) -> str:\n",
        "        \"\"\"Generate response from Ollama\"\"\"\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.1,  # Low temperature for structured extraction\n",
        "                \"top_p\": 0.9\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        if system_prompt:\n",
        "            payload[\"system\"] = system_prompt\n",
        "        \n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{self.base_url}/api/generate\",\n",
        "                json=payload,\n",
        "                timeout=self.timeout\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            return response.json()[\"response\"]\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Ollama generation failed: {e}\")\n",
        "\n",
        "# Initialize Ollama client\n",
        "ollama = OllamaClient(\n",
        "    CONFIG[\"OLLAMA_BASE_URL\"],\n",
        "    CONFIG[\"OLLAMA_MODEL\"],\n",
        "    CONFIG[\"TIMEOUT\"]\n",
        ")\n",
        "\n",
        "\n",
        "# ## MongoDB Connection\n",
        "\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"Handles MongoDB operations\"\"\"\n",
        "    \n",
        "    def __init__(self, uri: str, db_name: str):\n",
        "        self.client = MongoClient(uri)\n",
        "        self.db = self.client[db_name]\n",
        "        self._check_connection()\n",
        "    \n",
        "    def _check_connection(self):\n",
        "        \"\"\"Verify MongoDB connection\"\"\"\n",
        "        try:\n",
        "            self.client.admin.command('ping')\n",
        "            print(f\"âœ“ Connected to MongoDB: {self.db.name}\")\n",
        "        except ConnectionFailure as e:\n",
        "            raise ConnectionError(f\"MongoDB connection failed: {e}\")\n",
        "    \n",
        "    def create_institution(self, institution_data: dict) -> str:\n",
        "        \"\"\"Insert institution and return its ID\"\"\"\n",
        "        collection = self.db[CONFIG[\"COLLECTION_INSTITUTIONS\"]]\n",
        "        result = collection.insert_one(institution_data)\n",
        "        print(f\"âœ“ Institution created with ID: {result.inserted_id}\")\n",
        "        return str(result.inserted_id)\n",
        "    \n",
        "    def add_program(self, program: Program, institution_id: str):\n",
        "        \"\"\"Insert program into programs collection with institution_id reference\"\"\"\n",
        "        program_dict = program.model_dump()\n",
        "        program_dict[\"institution_id\"] = institution_id\n",
        "        result = self.db[CONFIG[\"COLLECTION_PROGRAMS\"]].insert_one(program_dict)\n",
        "        return str(result.inserted_id)\n",
        "\n",
        "# Initialize database manager\n",
        "db_manager = DatabaseManager(CONFIG[\"MONGODB_URI\"], CONFIG[\"DATABASE_NAME\"])\n",
        "\n",
        "\n",
        "# ## LLM Extraction Logic\n",
        "\n",
        "\n",
        "def extract_program_from_text(text: str, filename: str, max_retries: int = 2) -> Optional[Program]:\n",
        "    \"\"\"Extract program data from text using Ollama LLM\"\"\"\n",
        "    \n",
        "    system_prompt = \"\"\"\n",
        "You are an expert data extraction AI. Parse and follow the schema below. Your ONLY output must be a single valid JSON object using ONLY these field names (no others). Assign data to each field as described. If any extra data is found that does not fit the schema, include it as key-value pairs inside the 'extensions' object (use nested objects for complex/grouped data). Do NOT invent, rename, or omit any fields. Do NOT use fields like 'program', 'program_name', 'programmes', 'programs', or any other names. All fields must be present, and 'name' and 'confidence_score' are always required.\n",
        "\n",
        "If the input text is not about an academic program, or if you cannot extract a valid program name, SKIP it by returning only {\\\"not_relevant\\\": true} as the output. Never output null for 'name'.\n",
        "\n",
        "The 'level' field must always be a single string or null, never a list.\n",
        "\n",
        "NEVER use ellipsis (...) or any placeholder values in any field, including text fields. If a list, object, or text is too long or incomplete, include as much as possible, or use null, but never use ... or any invalid value.\n",
        "\n",
        "SCHEMA (field: type - assignment rule):\n",
        "{\n",
        "    \"name\": string, // Program name as stated in text (required)\n",
        "    \"program_code\": string or null, // Official code/identifier if mentioned, else null\n",
        "    \"description\": string or null, // Program overview, combine all relevant details\n",
        "    \"level\": string or null, // Academic level (e.g., Undergraduate, Postgraduate, Diploma, Certificate, Foundation), else null\n",
        "    \"duration\": object or null, // {\"years\": int, \"months\": int, \"weeks\": int} if mentioned, else null\n",
        "    \"delivery_mode\": array of strings or null, // [\"Full-time\", \"Part-time\", \"Online\", \"Hybrid\", \"Weekend\"] as mentioned, else null\n",
        "    \"fees\": object or null, // {\"amount\": number, \"currency\": string, \"period\": string, \"breakdown\": string or null} if mentioned, else null\n",
        "    \"eligibility\": object or null, // {\"minimum_qualifications\": string, \"gpa\": number or null, \"age_limit\": number or null, \"work_experience\": string or null, \"other_requirements\": array} if mentioned, else null\n",
        "    \"curriculum_summary\": string or null, // Overview of subjects/modules, else null\n",
        "    \"specializations\": array of strings or null, // List of tracks/majors, else null\n",
        "    \"url\": string or null, // Program or institution URL if present, else null\n",
        "    \"extensions\": object or null, // Any extra data not fitting above fields (use nested objects for complex/grouped data)\n",
        "    \"confidence_score\": float (0.0-1.0) // Extraction confidence (required, never null)\n",
        "}\n",
        "\n",
        "IMPORTANT:\n",
        "- Assign data to each field as per the rules above.\n",
        "- If a value is missing, use null (except for confidence_score, which must always be a float between 0 and 1).\n",
        "- Never include 'not_relevant' unless the output is exactly {\"not_relevant\": true}.\n",
        "- If the input text is not about an academic program, or if you cannot extract a valid program name, SKIP it by returning only {\"not_relevant\": true}.\n",
        "- The 'level' field must always be a single string or null, never a list.\n",
        "- NEVER use ellipsis (...) or any placeholder values in any field, including text fields. Only output valid JSON values. If a list, object, or text is too long or incomplete, include as much as possible, or use null, but never use ... or any invalid value.\n",
        "- Always output the correct type for each field.\n",
        "- Always close the JSON object with the correct number of closing braces at the end of your output. Do not leave the JSON incomplete.\n",
        "\n",
        "Remember: Your goal is COMPLETE extractionâ€”capture everything relevant!\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Extract ALL academic program information from the following text. Only extract if the text is truly about an academic program, course, or degree (such as undergraduate, postgraduate, diploma, certificate, or similar educational offering). If the text is not relevant to a program, course, or degree, or if you cannot extract a valid program name, SKIP it by returning only {{\\\"not_relevant\\\": true}} as the output. Never output null for 'name'.\n",
        "\n",
        "Parse and follow the schema and assignment rules below. Use ONLY these field names in your output. Do NOT invent or rename fields. Do NOT use fields like 'program', 'program_name', 'programmes', 'programs', or any other names. All fields must be present, and 'name' and 'confidence_score' are always required. If any URL is present in the text, assign it to the 'url' field in the output. Place all extra/unstructured data in the 'extensions' object (use nested objects for complex/grouped data). Return ONLY the JSON object, with no explanations, no markdown, and no extra text.\n",
        "\n",
        "The 'level' field must always be a single string or null, never a list.\n",
        "\n",
        "NEVER use ellipsis (...) or any placeholder values in any field, including text fields. If a list, object, or text is too long or incomplete, include as much as possible, or use null, but never use ... or any invalid value.\n",
        "\n",
        "SCHEMA (field: type - assignment rule):\n",
        "{{\n",
        "    \"name\": string, // Program name as stated in text (required)\n",
        "    \"program_code\": string or null, // Official code/identifier if mentioned, else null\n",
        "    \"description\": string or null, // Program overview, combine all relevant details\n",
        "    \"level\": string or null, // Academic level (e.g., Undergraduate, Postgraduate, Diploma, Certificate, Foundation), else null\n",
        "    \"duration\": object or null, // {{\"years\": int, \"months\": int, \"weeks\": int}} if mentioned, else null\n",
        "    \"delivery_mode\": array of strings or null, // [\"Full-time\", \"Part-time\", \"Online\", \"Hybrid\", \"Weekend\"] as mentioned, else null\n",
        "    \"fees\": object or null, // {{\"amount\": number, \"currency\": string, \"period\": string, \"breakdown\": string or null}} if mentioned, else null\n",
        "    \"eligibility\": object or null, // {{\"minimum_qualifications\": string, \"gpa\": number or null, \"age_limit\": number or null, \"work_experience\": string or null, \"other_requirements\": array}} if mentioned, else null\n",
        "    \"curriculum_summary\": string or null, // Overview of subjects/modules, else null\n",
        "    \"specializations\": array of strings or null, // List of tracks/majors, else null\n",
        "    \"url\": string or null, // Program or institution URL if present, else null\n",
        "    \"extensions\": object or null, // Any extra data not fitting above fields (use nested objects for complex/grouped data)\n",
        "    \"confidence_score\": float (0.0-1.0) // Extraction confidence (required, never null)\n",
        "}}\n",
        "\n",
        "TEXT:\n",
        "---\n",
        "{text}\n",
        "---\n",
        "IMPORTANT:\n",
        "- Carefully identify if the input text is truly about an academic program, course, or degree. If not, SKIP it by returning only {{\"not_relevant\": true}} as the output. Never output null for 'name'.\n",
        "- Assign data to each field as per the rules above.\n",
        "- If a value is missing, use null (except for confidence_score, which must always be a float between 0 and 1).\n",
        "- Never include 'not_relevant' unless the output is exactly {{\"not_relevant\": true}}.\n",
        "- The 'level' field must always be a single string or null, never a list.\n",
        "- NEVER use ellipsis (...) or any placeholder values in any field, including text fields. Only output valid JSON values. If a list, object, or text is too long or incomplete, include as much as possible, or use null, but never use ... or any invalid value.\n",
        "- Always output the correct type for each field.\n",
        "- Always close the JSON object with the correct number of closing braces at the end of your output. Do not leave the JSON incomplete.\n",
        "RETURN FORMAT: A single valid JSON object using only the allowed field names and types.\n",
        "\"\"\"\n",
        "\n",
        "    import re\n",
        "    def extract_first_json(text):\n",
        "        # Find the first {...} or [...] JSON object/array in the text\n",
        "        json_pattern = re.compile(r'({[\\s\\S]*})')\n",
        "        match = json_pattern.search(text)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "        return text.strip()\n",
        "\n",
        "    def try_repair_json(text):\n",
        "        # Try to auto-close the JSON object if it looks like it was cut off\n",
        "        # Count braces and add closing braces if needed\n",
        "        open_braces = text.count('{')\n",
        "        close_braces = text.count('}')\n",
        "        if open_braces > close_braces:\n",
        "            text = text + ('}' * (open_braces - close_braces))\n",
        "        return text\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            prompt_to_send = user_prompt\n",
        "            if attempt > 0 and 'last_validation_error' in locals():\n",
        "                prompt_to_send += f\"\\n\\nPREVIOUS VALIDATION ERROR:\\n{last_validation_error}\\nPlease correct your output to fix this error.\"\n",
        "            response = ollama.generate(prompt_to_send, system_prompt)\n",
        "            print(f\"âœ“ LLM response received for {response}\")\n",
        "            # Extract first valid JSON object from response\n",
        "            response = extract_first_json(response)\n",
        "            # Parse JSON\n",
        "            try:\n",
        "                data = json.loads(response)\n",
        "            except json.JSONDecodeError:\n",
        "                # Try to repair and parse again\n",
        "                repaired = try_repair_json(response)\n",
        "                try:\n",
        "                    data = json.loads(repaired)\n",
        "                except Exception as e:\n",
        "                    raise json.JSONDecodeError(str(e), repaired, 0)\n",
        "            # Check if not relevant\n",
        "            if data.get(\"not_relevant\"):\n",
        "                print(f\"âŠ˜ Skipped: {filename} (not program-related)\")\n",
        "                return None\n",
        "            # Validate with Pydantic\n",
        "            program = Program(**data)\n",
        "            # Skip low confidence extractions\n",
        "            if program.confidence_score < 0.5:\n",
        "                print(f\"âŠ˜ Skipped: {filename} (confidence too low: {program.confidence_score})\")\n",
        "                return None\n",
        "            return program\n",
        "        except json.JSONDecodeError as e:\n",
        "            if attempt < max_retries:\n",
        "                print(f\"âš  JSON parse error for {filename}, retrying... ({attempt+1}/{max_retries})\")\n",
        "                continue\n",
        "            print(f\"âœ— Failed to parse JSON for {filename}: {e}\")\n",
        "            return None\n",
        "        except ValidationError as e:\n",
        "            last_validation_error = str(e)\n",
        "            if attempt < max_retries:\n",
        "                print(f\"âš  Validation error for {filename}, retrying with error details... ({attempt+1}/{max_retries})\")\n",
        "                continue\n",
        "            print(f\"âœ— Validation error for {filename}: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Extraction error for {filename}: {e}\")\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "\n",
        "print(\"âœ“ Extraction functions ready\")\n",
        "\n",
        "\n",
        "# ## Main ETL Pipeline\n",
        "\n",
        "\n",
        "def run_etl_pipeline():\n",
        "    \"\"\"Main ETL pipeline execution\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ETL PIPELINE: Text Files â†’ Ollama LLM â†’ MongoDB\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "    # Step 1: Get institution details\n",
        "    print(\"STEP 1: Institution Setup\")\n",
        "    print(\"-\" * 70)\n",
        "    institution_name = input(\"Enter institution name: \").strip()\n",
        "    \n",
        "    if not institution_name:\n",
        "        print(\"âœ— Institution name is required!\")\n",
        "        return\n",
        "    \n",
        "    # Create institution\n",
        "    institution = Institution(\n",
        "        name=institution_name,\n",
        "        institution_code=f\"INST-{datetime.now().strftime('%Y%m%d')}\",\n",
        "        description=f\"Educational institution: {institution_name}\",\n",
        "        type=[\"University\"],\n",
        "        country=\"Sri Lanka\",\n",
        "        website=None,\n",
        "        recognition=None,\n",
        "        contact_info=None,\n",
        "        confidence_score=1.0\n",
        "    )\n",
        "    \n",
        "    institution_dict = institution.model_dump()\n",
        "    institution_dict[\"programs\"] = []  # Initialize empty programs array\n",
        "    institution_dict[\"created_at\"] = datetime.now()\n",
        "    \n",
        "    institution_id = db_manager.create_institution(institution_dict)\n",
        "    print(f\"âœ“ Institution ID: {institution_id}\\n\")\n",
        "    \n",
        "    # Step 2: Process text files\n",
        "    print(\"STEP 2: Processing Text Files\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    data_folder = Path(CONFIG[\"DATA_FOLDER\"])\n",
        "    \n",
        "    if not data_folder.exists():\n",
        "        print(f\"âœ— Data folder not found: {data_folder}\")\n",
        "        return\n",
        "    \n",
        "    text_files = list(data_folder.glob(\"*.txt\"))\n",
        "    \n",
        "    if not text_files:\n",
        "        print(f\"âœ— No .txt files found in {data_folder}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Found {len(text_files)} text file(s)\\n\")\n",
        "    \n",
        "    stats = {\n",
        "        \"total\": len(text_files),\n",
        "        \"processed\": 0,\n",
        "        \"skipped\": 0,\n",
        "        \"failed\": 0\n",
        "    }\n",
        "    \n",
        "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "    import threading\n",
        "\n",
        "    print(f\"\\nUsing parallel processing with ThreadPoolExecutor ({min(8, len(text_files))} workers)...\\n\")\n",
        "\n",
        "    stats_lock = threading.Lock()\n",
        "\n",
        "    def process_file(idx_file_tuple):\n",
        "        idx, file_path = idx_file_tuple\n",
        "        print(f\"[{idx}/{len(text_files)}] Processing: {file_path.name}\")\n",
        "        try:\n",
        "            text_content = file_path.read_text(encoding=\"utf-8\").strip()\n",
        "            if not text_content:\n",
        "                print(f\"âŠ˜ Skipped: Empty file\\n\")\n",
        "                with stats_lock:\n",
        "                    stats[\"skipped\"] += 1\n",
        "                return\n",
        "            program = extract_program_from_text(text_content, file_path.name, CONFIG[\"MAX_RETRIES\"])\n",
        "            if program is None:\n",
        "                with stats_lock:\n",
        "                    stats[\"skipped\"] += 1\n",
        "                print()\n",
        "                return\n",
        "            program_dict = program.model_dump()\n",
        "            program_dict[\"source_file\"] = file_path.name\n",
        "            program_dict[\"extracted_at\"] = datetime.now()\n",
        "            program_id = db_manager.add_program(program, institution_id)\n",
        "            print(f\"âœ“ Added program: {program.name} (id: {program_id}, confidence: {program.confidence_score:.2f})\\n\")\n",
        "            with stats_lock:\n",
        "                stats[\"processed\"] += 1\n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Error processing {file_path.name}: {e}\\n\")\n",
        "            with stats_lock:\n",
        "                stats[\"failed\"] += 1\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=min(8, len(text_files))) as executor:\n",
        "        futures = [executor.submit(process_file, (idx, file_path)) for idx, file_path in enumerate(text_files, 1)]\n",
        "        for future in as_completed(futures):\n",
        "            pass  # All output is handled in process_file\n",
        "    \n",
        "    # Step 3: Summary\n",
        "    print(\"=\"*70)\n",
        "    print(\"PIPELINE SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Total files:     {stats['total']}\")\n",
        "    print(f\"âœ“ Processed:     {stats['processed']}\")\n",
        "    print(f\"âŠ˜ Skipped:       {stats['skipped']}\")\n",
        "    print(f\"âœ— Failed:        {stats['failed']}\")\n",
        "    print(f\"\\nInstitution ID:  {institution_id}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ## Execute Pipeline\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        run_etl_pipeline()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nâœ— Pipeline interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nâœ— Pipeline failed: {e}\")\n",
        "        raise"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
